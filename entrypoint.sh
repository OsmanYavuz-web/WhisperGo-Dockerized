#!/bin/bash
set -e

# Default Settings
MODEL="${WHISPER_MODEL:-ggml-base.bin}"
LANG="${WHISPER_LANGUAGE:-tr}"
HOST="${WHISPER_HOST:-0.0.0.0}"
PORT="${WHISPER_PORT:-8080}"
MODEL_PATH="/app/models/${MODEL}"

# Model Download Logic
if [ ! -f "${MODEL_PATH}" ]; then
    echo "â¬‡ï¸  Model indirilmesi gerekiyor: ${MODEL}"
    
    # Extract model type (e.g., ggml-base.bin -> base)
    MODEL_TYPE=$(echo "${MODEL}" | sed "s/ggml-//;s/\.bin//")
    
    echo "ğŸ” Model Tipi: ${MODEL_TYPE}"
    
    # Use the script from whisper.cpp repo structure
    # Note: We need to make sure this script exists in the runtime container
    if [ -f "/app/download-ggml-model.sh" ]; then
        bash /app/download-ggml-model.sh "${MODEL_TYPE}" /app/models
    else
        echo "âŒ Hata: Ä°ndirme scripti bulunamadÄ±!"
        exit 1
    fi
else
    echo "âœ… Model mevcut: ${MODEL}"
fi

echo "ğŸš€ WhisperGo-Dockerized BaÅŸlatÄ±lÄ±yor..."
echo "----------------------------------------"
echo "ğŸ§  Model: ${MODEL}"
echo "ğŸ—£ï¸  Dil:   ${LANG}"
echo "ğŸ§ Port:  ${PORT}"
echo "ğŸ“ Mode:  CLI (her istekte model yÃ¼klenir)"
echo "----------------------------------------"

# Run the CLI API (unbuffered for immediate log output)
exec python3 -u /app/cli-api.py


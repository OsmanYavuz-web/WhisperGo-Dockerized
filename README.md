# ğŸ³ WhisperGo-Dockerized

Bu proje, OpenAI'nin Whisper modelinin yÃ¼ksek performanslÄ± C/C++ implementasyonu olan [whisper.cpp](https://github.com/ggml-org/whisper.cpp) Ã¼zerine inÅŸa edilmiÅŸ, Dockerize edilmiÅŸ, baÄŸÄ±msÄ±z ve hafif bir API servisidir.

## âœ¨ Ã–zellikler

*   ğŸš€ **YÃ¼ksek Performans:** C/C++ tabanlÄ± motor, Multi-Stage build ile optimize edilmiÅŸ imaj.
*   ğŸ‹ **Docker Ready:** Tek komutla (Docker Compose) ayaÄŸa kalkmaya hazÄ±r.
*   ğŸ”’ **GÃ¼venli:** Non-root (yetkisiz) kullanÄ±cÄ± ile Ã§alÄ±ÅŸarak prodÃ¼ksiyon gÃ¼venliÄŸi saÄŸlar.
*   ğŸŒ **REST API:** Kolay entegrasyon iÃ§in hazÄ±r HTTP server.
*   ğŸ–¥ï¸ **Web ArayÃ¼zÃ¼:** Ses dosyalarÄ±nÄ± tarayÄ±cÄ± Ã¼zerinden test etmek iÃ§in yerleÅŸik arayÃ¼z.
*   ğŸŒ **Ã‡ok Dilli:** TÃ¼rkÃ§e dahil 99+ dilde yÃ¼ksek doÄŸrulukta transkripsiyon.
*   ğŸ“¦ **Standalone:** Harici hiÃ§bir kÃ¼tÃ¼phaneye veya baÄŸÄ±mlÄ±lÄ±ÄŸa ihtiyaÃ§ duymaz.
*   ğŸ’¾ **CLI Mode:** Her istekte model yÃ¼klenir, bellek sadece iÅŸlem sÄ±rasÄ±nda kullanÄ±lÄ±r.

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

Projeyi ayaÄŸa kaldÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:

```bash
# Servisi baÅŸlat (Model yoksa otomatik indirilecektir)
docker-compose up -d --build

# LoglarÄ± takip et
docker-compose logs -f
```

Server varsayÄ±lan olarak `http://localhost:6666` adresinde Ã§alÄ±ÅŸÄ±r.

## âš™ï¸ YapÄ±landÄ±rma

YapÄ±landÄ±rma iÃ§in `.env` dosyasÄ±nÄ± kullanabilirsiniz. EÄŸer yoksa `.env.example` dosyasÄ±nÄ± kopyalayarak oluÅŸturun:

```bash
cp .env.example .env
```

### `.env` DeÄŸiÅŸkenleri:

| DeÄŸiÅŸken | AÃ§Ä±klama | VarsayÄ±lan |
|----------|----------|------------|
| `PORT` | DÄ±ÅŸ eriÅŸim portu | `6666` |
| `WHISPER_PORT` | Ä°Ã§ WhisperGo portu | `6666` |
| `WHISPER_HOST` | Bind adresi | `0.0.0.0` |
| `WHISPER_MODEL` | KullanÄ±lacak model | `ggml-base.bin` |
| `WHISPER_LANGUAGE` | VarsayÄ±lan dil | `tr` |

### Environment deÄŸiÅŸikliklerini yaptÄ±ktan sonra servisi gÃ¼ncellemek iÃ§in:

```bash
docker-compose up -d
```

### Mevcut Modeller:

| Model | Boyut | Not |
|-------|-------|-----|
| `ggml-tiny.bin` | 75 MB | âš¡ En HÄ±zlÄ± |
| `ggml-base.bin` | 142 MB | âœ… Dengeli (Ã–nerilen) |
| `ggml-small.bin` | 466 MB | â­ Ä°yi DoÄŸruluk |
| `ggml-medium.bin` | 1.5 GB | ğŸ¯ YÃ¼ksek DoÄŸruluk |
| `ggml-large-v3-turbo.bin` | 1.5 GB | ğŸš€ HÄ±zlÄ± & GÃ¼Ã§lÃ¼ |

## ğŸ’¾ CLI Mode (Bellek Optimize)

WhisperGo **CLI Mode** ile Ã§alÄ±ÅŸÄ±r:

- Her istek iÃ§in model yÃ¼klenir
- Ä°ÅŸlem bitince bellek serbest kalÄ±r
- Avantaj: RAM sadece iÅŸlem sÄ±rasÄ±nda kullanÄ±lÄ±r
- Dezavantaj: Her istek ~2-5 saniye ekstra (model yÃ¼kleme)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            HER Ä°STEKTE                  â”‚
â”‚                                         â”‚
â”‚  1. Model yÃ¼klenir (~2-5s)              â”‚
â”‚  2. Ses dosyasÄ± iÅŸlenir                 â”‚
â”‚  3. SonuÃ§ dÃ¶ndÃ¼rÃ¼lÃ¼r                    â”‚
â”‚  4. Bellek serbest kalÄ±r                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¡ API KullanÄ±mÄ±

### Ses DosyasÄ± GÃ¶nderme (cURL)

```bash
curl http://localhost:6666/inference \
  -H "Content-Type: multipart/form-data" \
  -F file="@ses-dosyasi.wav" \
  -F language="tr" \
  -F response_format="json"
```

### Health Check

```bash
curl http://localhost:6666/health
```

## ğŸ“ KlasÃ¶r YapÄ±sÄ±

```text
WhisperGo-Dockerized/
â”œâ”€â”€ Dockerfile          # Multi-Stage build tanÄ±mÄ± (Builder & Runtime)
â”œâ”€â”€ docker-compose.yml  # Servis orkestrasyonu
â”œâ”€â”€ entrypoint.sh       # Konteyner baÅŸlangÄ±Ã§ ve model kontrol scripti
â”œâ”€â”€ cli-api.py          # CLI mode API handler
â”œâ”€â”€ .env                # YapÄ±landÄ±rma (Git-ignored)
â”œâ”€â”€ .env.example        # Ã–rnek yapÄ±landÄ±rma
â””â”€â”€ models/             # Ä°ndirilen modeller (KalÄ±cÄ± depolama)
```

## ğŸ› ï¸ Teknik Notlar

*   **Multi-Stage Build:** Ä°maj boyutu optimize edilmiÅŸtir, gereksiz derleme araÃ§larÄ± son imajda bulunmaz.
*   **Security Context:** Konteyner `whisper` adÄ±nda non-root bir kullanÄ±cÄ± ile Ã§alÄ±ÅŸÄ±r.
*   **CLI Mode:** Her istekte `whispergo-cli` Ã§aÄŸrÄ±lÄ±r, model bellekte tutulmaz.
*   Servis baÅŸlatÄ±ldÄ±ÄŸÄ±nda seÃ§ili model `models/` klasÃ¶rÃ¼nde yoksa otomatik olarak Hugging Face Ã¼zerinden indirilir.

## ğŸ‘¤ HazÄ±rlayan

**HazÄ±rlayan:** Osman Yavuz  
**ğŸ“§ E-posta:** omnyvz.yazilim@gmail.com